{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/domschl/torch-transformer-poet/blob/main/torch_transformer_poet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEXNOWhCEAPk"
   },
   "source": [
    "# Torch-Transformer-Poet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DabS0VZ-1Zp0"
   },
   "source": [
    "Please review [ml-indie-tools](https://github.com/domschl/ml-indie-tools), a collection machine learning tools that provides support for more environment indepent code. It will access your Google Drive when using with Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gF-7qFzMdnN1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ml-indie-tools in ./lib/python3.12/site-packages (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ml-indie-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jtpy59Yq-Qfz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # from: https://github.com/pytorch/pytorch/issues/107960  (libcuda not found)\n",
    "    !export LC_ALL=\"en_US.UTF-8\"\n",
    "    !export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
    "    !export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
    "    !ldconfig /usr/lib64-nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EgLLjG4yQtft"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U5T4m6earb1e"
   },
   "outputs": [],
   "source": [
    "from ml_indie_tools.env_tools import MLEnv\n",
    "from ml_indie_tools.Gutenberg_Dataset import Gutenberg_Dataset\n",
    "from ml_indie_tools.Text_Dataset import Text_Dataset\n",
    "\n",
    "from ml_indie_tools.Calibre_Dataset import Calibre_Dataset\n",
    "from ml_indie_tools.Folder_Dataset import Folder_Dataset\n",
    "\n",
    "import ml_indie_tools.pytorch_meta_tools as MJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jVcwvURB5EZN"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.Logger(\"Main\")\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmWbteSFQtfq"
   },
   "source": [
    "## Preliminary\n",
    "\n",
    "A pytorch deep multi-head attention model for text generation following Andrej Karpathy's [video-lecture-ng](https://github.com/karpathy/ng-video-lecture/blob/master/gpt.py)\n",
    "\n",
    "This code can use either CPU, GPU, or Apple Silicon. Google Colab is supported too, select the corresponding Colab runtime (menu: **`Runtime / Change runtime type`**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfZg31sMEAP1"
   },
   "source": [
    "## 0. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "llPw84PkEAP2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OS: Linux, Python: 3.12.3, Jupyter Notebook Pytorch: 2.4.0.dev20240501+cu121, GPU: NVIDIA GeForce RTX 4070 Ti (/  285W |       4MiB), CPU'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_batch_data = None   # Do regenerate time-consuming training data, if aleady cached.\n",
    "\n",
    "ml_env = MLEnv(platform='pt', accelerator='fastest')\n",
    "ml_env.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qg3ZPBmC8kO"
   },
   "source": [
    "## 1. Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t-TP3Pnsrb1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root path (all projects) : . (This will be '.' (current dir) for local projects, and a google drive path for Colab)\n",
      "Project path             : . (Changes to the file system happen only below this project path\n",
      "Model path (snapshots)   : ./model/tr_neo_philosophers_v3_pt (Model weights and snapshots are stored here)\n",
      "Data path (training data): ./data (Training data will be downloaded here)\n",
      "Log dir (tensorboard)    : ./logs (it doesn't work to put logs on gdrive due to caching, hence local dir)\n"
     ]
    }
   ],
   "source": [
    "# project_name = 'women_writers'\n",
    "# project_name='research'\n",
    "project_name='neo_philosophers'\n",
    "model_cpu = None\n",
    "model_name=f'tr_{project_name}_v3_pt'\n",
    "\n",
    "use_preprocessed_data = True                      # Use already tokenized data\n",
    "use_existing_model_from_checkpoint = False         # Try to load checkpoint of training\n",
    "use_torch_compile = False                           # Requires a modern graphics card with torch compile backend support\n",
    "skip_additional_texts = True                       # Don't look for other data sources in `additional_texts.json`\n",
    "\n",
    "if 'google.colab' in sys.modules:  # Google colab notebooks run on server that provide UTC time, we adapt logs to local time:\n",
    "    local_timezone = ZoneInfo('Europe/Berlin')\n",
    "else:\n",
    "    local_timezone = None\n",
    "\n",
    "# NOTICE: This will request access to Google Drive, if running on Google Colab. Google Drive is used to store snapshots\n",
    "# training data. See project ml-indie-tools: https://github.com/domschl/ml-indie-tools\n",
    "#\n",
    "# Note: you need to allow popups in your browser for COLAB, otherwise you won't see the google-drive login box, and drive access will fail!\n",
    "\n",
    "root_path, project_path, model_path, data_path, log_path = ml_env.init_paths(project_name=project_name, model_name=model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else device\n",
    "\n",
    "print(f\"Root path (all projects) : {root_path} (This will be '.' (current dir) for local projects, and a google drive path for Colab)\")\n",
    "print(f\"Project path             : {project_path} (Changes to the file system happen only below this project path\")\n",
    "print(f\"Model path (snapshots)   : {model_path} (Model weights and snapshots are stored here)\")\n",
    "print(f\"Data path (training data): {data_path} (Training data will be downloaded here)\")\n",
    "print(f\"Log dir (tensorboard)    : {log_path} (it doesn't work to put logs on gdrive due to caching, hence local dir)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIkcYcEuQtfx"
   },
   "source": [
    "##  2.1 Text data from Project Gutenberg\n",
    "\n",
    "`Text_Dataset` and `Gutenberg_Dataset` classes: libraries for training,\n",
    "encoding, batch generation, and formatted source display. It read some\n",
    "books from Project Gutenberg and supports creation of training batches.\n",
    "The output functions support highlighting to allow to compare generated\n",
    "texts with the actual sources to help to identify identical (memorized)\n",
    "parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HjkelBcNO5WV"
   },
   "outputs": [],
   "source": [
    "use_dark_mode=False # Set to false for white background. HTML-text-compare uses background-colorization to identify different sources. Those background colors are dependent on the theme type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BF8eyWnCrb1h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Datasets:Loading tokenizer from ./data/neo_philosophers_tokens.json\n",
      "INFO:Datasets:Loading tokenizer done.\n"
     ]
    }
   ],
   "source": [
    "token_file = os.path.join(data_path,f\"{project_name}_tokens.json\")\n",
    "if use_preprocessed_data is True:\n",
    "    if os.path.exists(token_file):\n",
    "        td = Text_Dataset()\n",
    "        td.load_tokenizer(token_file)\n",
    "    else:\n",
    "        use_preprocessed_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C66X7ynnrb1h"
   },
   "outputs": [],
   "source": [
    "if use_preprocessed_data is False:\n",
    "    cache_dir = os.path.join(data_path, 'gutenberg_cache')\n",
    "    gd = Gutenberg_Dataset(cache_dir=cache_dir)\n",
    "\n",
    "    if project_name == 'women_writers':  # sample searches\n",
    "        search_spec= {\n",
    "            \"author\": [\"Emily Brontë\", \"Jane Austen\", \"Virginia Woolf\"],\n",
    "            \"language\": [\"english\"]\n",
    "        }\n",
    "        book_list=gd.search(search_spec)\n",
    "    elif project_name == 'neo_philosophers':\n",
    "        search_spec = {\n",
    "            \"author\": [\"Immanuel Kant\", \"Friedrich Nietzsche\", \"Wilhelm Hegel\", \"Arthur Schopenhauer\"],\n",
    "            \"language\": [\"english\", \"german\"]\n",
    "        }\n",
    "        book_list=gd.search(search_spec)\n",
    "        search_spec = {\n",
    "            \"author\": [\"Plato\", \"Platon\"],\n",
    "            \"title\": [\"Timaeus\", \"Critias\", \"Symposium\"],\n",
    "            \"language\": [\"english\", \"german\"]\n",
    "        }\n",
    "        book_list+=gd.search(search_spec)\n",
    "        search_spec = {\n",
    "            \"title\": [\"Buddh\", \"Sutra\"],\n",
    "            \"language\": [\"english\", \"german\"]\n",
    "        }\n",
    "        book_list+=gd.search(search_spec)\n",
    "    else:\n",
    "        search_spec = {}\n",
    "        book_list = []\n",
    "\n",
    "    book_cnt = len(book_list)\n",
    "    print(f\"{book_cnt} matching books found with search {search_spec}.\")\n",
    "\n",
    "    if book_cnt > 0:\n",
    "        if book_cnt<80:\n",
    "            # Note: please verify that book_cnt is 'reasonable'. If you plan to use a large number of texts,\n",
    "            # consider [mirroring Gutenberg](https://github.com/domschl/ml-indie-tools#working-with-a-local-mirror-of-project-gutenberg)\n",
    "            book_list = gd.insert_book_texts(book_list, download_count_limit=book_cnt)\n",
    "        else:\n",
    "            logging.error(\"Please verify your book_list, a large number of books is scheduled for download. ABORTED.\")\n",
    "\n",
    "        for i in range(len(book_list)):\n",
    "            if 'author' not in book_list[i]:\n",
    "                book_list[i]['author']='unknown'\n",
    "            print(f\"{i}: {book_list[i]['title']} - {book_list[i]['author']}, {book_list[i]['ebook_id']}\")\n",
    "\n",
    "        if project_name == 'women_writers':\n",
    "            select = (\"Bennett\", \"1342\", \"5670\", \"1245\", \"161\", \"141\", \"121\", \"105\", \"Susan\", \"Wuthering\", \"Emma\", \"Voyage\")  # List unique single-words from title or ebook_id to select a given book\n",
    "            sub_book_list = [book_list[i] for i in range(len(book_list)) if not set([book_list[i]['ebook_id']]+book_list[i]['title'].split(' ')).isdisjoint(set(select))]\n",
    "        else:\n",
    "            sub_book_list = book_list\n",
    "\n",
    "        print(\"Using:\")\n",
    "        for i in range(len(sub_book_list)):\n",
    "            if 'author' not in sub_book_list[i]:\n",
    "                sub_book_list[i]['author']='unknown'\n",
    "            print(f\"{i+1}: {sub_book_list[i]['title']} - {sub_book_list[i]['author']}\")\n",
    "\n",
    "        td = Text_Dataset(sub_book_list)\n",
    "    else:\n",
    "        td = Text_Dataset()()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxNIc7gL9UNg"
   },
   "source": [
    "## 2.2 Additional training material from folders or Calibre library\n",
    "\n",
    "This looks for a file `additional_texts.json` in the `project_path` as shown above.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"local_texts\": [\"/some/directory/that/contains/texts\"],\n",
    "  \"calibre\": \"/home/myuser/Calibre Library\"\n",
    "}\n",
    "```\n",
    "\n",
    "If the folder(s) defined in `local_texts` contain text files with default endings `.txt`, `.md`, `.org`, or `.py` (can be configured), they are added to the training data. Folders are searched recursively.\n",
    "\n",
    "If the path defined in `calibre` contains a Calibre database, all text files (`.txt` only) within that library are added to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1NYdjlW65EZP"
   },
   "outputs": [],
   "source": [
    "if use_preprocessed_data is False and skip_additional_texts is False:\n",
    "    additional = os.path.join(project_path, \"additional_texts.json\")\n",
    "    print(f\"Looking for description of additional sources in {additional}\")\n",
    "    if os.path.exists(additional) is True:\n",
    "        with open(additional, 'r') as f:\n",
    "            add_desc = json.load(f)\n",
    "            if 'local_texts' in add_desc:\n",
    "                fd = Folder_Dataset()\n",
    "                for text_path in add_desc['local_texts']:\n",
    "                    print(f\"Loading texts from {text_path}\")\n",
    "                    fd.load_index(text_path, use_aliases=False, max_file_size=100000)\n",
    "                td.load_texts(fd.records[:10000])\n",
    "            if 'calibre' in add_desc:\n",
    "                cal_path = add_desc['calibre']\n",
    "                if os.path.exists(cal_path):\n",
    "                    print(f\"Loading text from calibre at {cal_path}\")\n",
    "                    cd = Calibre_Dataset(cal_path)\n",
    "                    cd.load_index(max_file_size=100000000)\n",
    "                    td.load_texts(cd.records[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSm4f9NSC8kQ"
   },
   "source": [
    "## 2.3 Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bsyBjqFyC8kQ"
   },
   "outputs": [],
   "source": [
    "if use_preprocessed_data is False:\n",
    "    MAX_TOKENS = 10000  # This becomes vocab_size\n",
    "    MAX_NGRAM_LEN = 4   # Max length of a token\n",
    "    CHUNK_SIZE = 500000 # Split larger texts in chunks, if not None\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Starting tokenizer with token length from 1..{MAX_NGRAM_LEN} with a max of {MAX_TOKENS} unique tokens,\")\n",
    "    print(\"this can take considerable time...\")\n",
    "\n",
    "    # Better tested NGRAM tokenizer:\n",
    "    # td.init_tokenizer(tokenizer='ngram', max_ngrams=MAX_NGRAM_LEN, max_tokens=MAX_TOKENS) \n",
    "    # or alternative 'BYTEGRAM' (more experimental, can encode arbitrary UTF-8)\n",
    "    # td.init_tokenizer(tokenizer='bytegram', max_ngrams=MAX_NGRAM_LEN, max_tokens=MAX_TOKENS, chunk_size=CHUNK_SIZE)\n",
    "    td.init_tokenizer(tokenizer='bytegram', max_ngrams=MAX_NGRAM_LEN, max_tokens=MAX_TOKENS, chunk_size=CHUNK_SIZE)\n",
    "    td.save_tokenizer(token_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MG03WA_yC8kR"
   },
   "source": [
    "## 3. Model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UPMwIn2gC8kR"
   },
   "outputs": [],
   "source": [
    "params = None\n",
    "updatable_keys=['learning_rate', 'batch_size', 'current_epoch', 'current_loss',\n",
    "                 'sample_every_n_iterations', 'sample_size', 'save_every_n_iterations', 'max_iterations']\n",
    "attn_layers = 4\n",
    "dims = 256\n",
    "sequence_length = 96\n",
    "\n",
    "params = { # Multi-head self-attention\n",
    "        'meta_name_template': '{mhsa_layers}x{heads}x{units}x{vocab_size}',\n",
    "\n",
    "        'mhsa_layers': attn_layers,\n",
    "        'heads': 8,\n",
    "        'vocab_size': td.get_unique_token_count(),\n",
    "        'sequence_len': sequence_length,\n",
    "        'dropout': 0.1,\n",
    "        'embedding_size': dims,\n",
    "        'test_iterations': 20,  # number of epocs for loss estimation\n",
    "        'use_recur': False,\n",
    "\n",
    "        'batch_size': 256,      \n",
    "        'learning_rate': 3e-4,   # None: Set in dependence of graphics hw\n",
    "\n",
    "        'sample_every_n_iterations': 2048,\n",
    "        'sample_size': 128,\n",
    "        'save_every_n_iterations': 4096,\n",
    "\n",
    "        'max_iterations': 100000000  # maximum number of training iterations\n",
    "    }\n",
    "\n",
    "model_file_path = MJ.get_model_filename(model_path)\n",
    "if use_existing_model_from_checkpoint is True:\n",
    "    params = MJ.load_model_metadata_from_checkpoint(params, updatable_keys, model_file_path, device=device, log=log) # torch.device('cpu'))\n",
    "if params == None or use_existing_model_from_checkpoint is False:\n",
    "    use_existing_model_from_checkpoint = False\n",
    "# print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U1R4yDlC8kR"
   },
   "source": [
    "## 4. Batch handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f7_tc2Lirb1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15392802 records\n"
     ]
    }
   ],
   "source": [
    "joint_training=0\n",
    "td.init_getitem(sample_type='encoded', sample_length=params['sequence_len']+1+joint_training, content_stepping=1)\n",
    "num_records = len(td)\n",
    "print(f\"{num_records} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zZbbsNm0cOeW"
   },
   "outputs": [],
   "source": [
    "def get_sample_sub_batch(sample_batch, batch_size, sub_index=0):\n",
    "    joint_training=0\n",
    "    for i in range(batch_size):\n",
    "        Xi = sample_batch[sub_index:-1-joint_training+sub_index]\n",
    "        yi = sample_batch[sub_index+1:]\n",
    "        if i==0:\n",
    "            # smpX=np.array(Xi, dtype=np.float32)\n",
    "            smpX=np.array(Xi, dtype=np.int32)\n",
    "            smpy=np.array(yi, dtype=np.int32)\n",
    "        else:\n",
    "            # smpX = np.vstack((smpX, np.array(Xi, dtype=np.float32)))\n",
    "            smpX = np.vstack((smpX, np.array(Xi, dtype=np.int32)))\n",
    "            smpy = np.vstack((smpy, np.array(yi, dtype=np.int32)))\n",
    "    return np.array(smpX), np.array(smpy)\n",
    "\n",
    "def get_sample_batch(td, batch_size):\n",
    "    sample_batch = td.get_random_item()\n",
    "    return get_sample_sub_batch(sample_batch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jY3hUuhQYzdT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches = 60128\n"
     ]
    }
   ],
   "source": [
    "num_batches = num_records // params['batch_size']\n",
    "print(f\"num_batches = {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 96), (2, 96))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_sample_batch(td, 2)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bgVHUkbhdK9y"
   },
   "outputs": [],
   "source": [
    "sample_data = None\n",
    "\n",
    "def get_torch_subbatch(td, batch_size, device, split=None, sub_index=0):\n",
    "    global sample_data\n",
    "    if sub_index==0:\n",
    "        sample_data = td.get_random_item()\n",
    "    x, y = get_sample_sub_batch(sample_data, batch_size, sub_index)\n",
    "    tx = torch.tensor(x, dtype=torch.long).to(device)\n",
    "    tx.requires_grad = False\n",
    "    ty = torch.tensor(y, dtype=torch.long).to(device)\n",
    "    ty.requires_grad = False\n",
    "    return tx, ty\n",
    "\n",
    "def get_torch_batch(td, batch_size, device, split=None):\n",
    "    x, y = get_sample_batch(td, batch_size)\n",
    "    tx = torch.tensor(x, dtype=torch.long).to(device)\n",
    "    tx.requires_grad = False\n",
    "    ty = torch.tensor(y, dtype=torch.long).to(device)\n",
    "    ty.requires_grad = False\n",
    "    return tx, ty\n",
    "\n",
    "def get_zero_state(batch_size, sequence_len, hidden_size, device):\n",
    "    zstate = torch.zeros(batch_size, sequence_len, hidden_size, device=device)\n",
    "    zstate.requires_grad = False\n",
    "    return zstate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pvbi6kjXC8kS"
   },
   "source": [
    "## 5. Loss and training helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000, device=None):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model, device=device)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "        \n",
    "class MultiHeadSelfAttentionWithMemory(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_size,\n",
    "        sequence_len,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        dropout=0.1,\n",
    "        use_recur=False,\n",
    "        device=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if device is None:\n",
    "            raise ValueError(\n",
    "                \"Device is None at MultiHeadSelfAttentionWithMemory\"\n",
    "            )\n",
    "        self.device = device\n",
    "        self.sequence_len = sequence_len\n",
    "        self.use_recur = use_recur\n",
    "        context_sub_layers = num_layers // 2\n",
    "        self.context_sub_layers = context_sub_layers\n",
    "        dims = embedding_size\n",
    "        self.dims = dims\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, device=device)\n",
    "        with torch.no_grad():\n",
    "            self.position_embedding_table = nn.Embedding(\n",
    "                sequence_len, embedding_size, device=device\n",
    "            )\n",
    "\n",
    "        # self.pos_encoder = PositionalEncoding(dims, dropout=0.0, max_len=10000, device=device)\n",
    "        self.out_proj = nn.Linear(dims, vocab_size, device=device)\n",
    "\n",
    "        if use_recur is True:\n",
    "            self.rec=nn.RNN(dims, dims, num_layers=3, batch_first=True, device=device)\n",
    "            self.lq=nn.Linear(dims, dims, device=device)\n",
    "            self.lk=nn.Linear(dims, dims, device=device)\n",
    "            self.lv=nn.Linear(dims, dims, device=device)\n",
    "            self.lnorm=nn.BatchNorm1d(dims, device=device)\n",
    "            self.sm = nn.Softmax(dim=2)\n",
    "            self.proj1 = nn.Linear(dims, dims, device=device)\n",
    "            self.sm2 = nn.Softmax(dim=2)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model=dims, nhead=num_heads, dim_feedforward=dims*4, dropout=dropout, batch_first=True, device=device)\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=context_sub_layers)\n",
    "            encoder_layer2 = nn.TransformerEncoderLayer(d_model=dims, nhead=num_heads, dim_feedforward=dims*4, dropout=dropout, batch_first=True, device=device)\n",
    "            self.transformer2 = nn.TransformerEncoder(encoder_layer2, num_layers=num_layers - context_sub_layers)\n",
    "        else:\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model=dims, nhead=num_heads, dim_feedforward=dims*4, dropout=dropout, batch_first=True, device=device)\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.out_proj.bias.data.zero_()\n",
    "        self.out_proj.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        B, D = idx.shape\n",
    "        tok_emb = self.embedding(idx)\n",
    "        # idx and targets are both (B,D) tensor of integers\n",
    "        # tok_emb = self.token_embedding_table(idx)  # (B,D,C)\n",
    "\n",
    "        # XXX: move to init, make not trainable:\n",
    "        if self.device is None:\n",
    "            pos_emb = self.position_embedding_table(torch.arange(self.sequence_len))\n",
    "        else:\n",
    "            pos_emb = self.position_embedding_table(\n",
    "                torch.arange(D, device=self.device)\n",
    "            )  # (D,C)\n",
    "\n",
    "        x = tok_emb + pos_emb  # (B,D,C)\n",
    "        \n",
    "        # x = self.pos_encoder(x) \n",
    "        x_mask = nn.Transformer.generate_square_subsequent_mask(D).to(self.device)\n",
    "        x = self.transformer(x, x_mask)\n",
    "\n",
    "        if self.use_recur is True:\n",
    "            skip = x\n",
    "            x = self.rec(x)[0] + x\n",
    "            xk = self.lk(x).permute((0,2,1))\n",
    "            xv = self.lv(x)\n",
    "            xq = self.lq(x)\n",
    "            xqk = torch.matmul(xq, xk)\n",
    "            sm = self.sm(xqk)/math.sqrt(D)\n",
    "            att = torch.matmul(sm, xv)\n",
    "            x = self.lnorm(att)\n",
    "            x = self.sm2(self.proj1(x))\n",
    "            x = x + skip    \n",
    "            x = self.transformer2(x, x_mask)\n",
    "            \n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"Generate new tokens given a context\n",
    "\n",
    "        Note: for apple MPS, top_k is limited max 16 vor older torchs! ((01/2023) implementation limitation)\n",
    "        See: https://github.com/pytorch/pytorch/issues/78915\n",
    "        Solved in: https://github.com/pytorch/pytorch/pull/94639 (03/2023)\n",
    "\n",
    "        :param idx: the context (B,T) tensor of indices\n",
    "        :param max_new_tokens: the maximum number of tokens to generate\n",
    "        :param temperature: the temperature to use for sampling\n",
    "        :param top_k: the number of top tokens to consider\n",
    "        \"\"\"\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last sequence_len tokens\n",
    "            idx_cond = idx[:, -self.sequence_len :]\n",
    "            # print(idx_cond.shape)\n",
    "            # get the predictions\n",
    "            logits = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply temperature\n",
    "            if temperature != 1.0 and temperature > 0.0:\n",
    "                logits = logits / temperature\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pdaulm1VdK9z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "MultiHeadSelfAttentionWithMemory(\n",
      "  (embedding): Embedding(10000, 256)\n",
      "  (position_embedding_table): Embedding(96, 256)\n",
      "  (out_proj): Linear(in_features=256, out_features=10000, bias=True)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "8.313616 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"creating model...\")\n",
    "try:\n",
    "    # Colab + torch 2 -> lots of garbage.\n",
    "    if model is not None:\n",
    "        del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "model = MultiHeadSelfAttentionWithMemory(vocab_size=params['vocab_size'], embedding_size=params['embedding_size'],\n",
    "                                       sequence_len=params['sequence_len'],\n",
    "                                       num_heads=params['heads'], num_layers=params['mhsa_layers'], dropout=params['dropout'],\n",
    "                                       use_recur=params['use_recur'], device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "model = model.to(device)\n",
    "if use_existing_model_from_checkpoint is True:\n",
    "    params_load = MJ.load_checkpoint(params, model, optimizer, file_path=model_file_path, updatable_keys=updatable_keys, device=device, log=log) # torch.device(\"cpu\"))\n",
    "    if params_load is not None:\n",
    "        params = params_load\n",
    "model = model.to(device)\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)\n",
    "\n",
    "if use_torch_compile is True:\n",
    "    if device == 'cuda':\n",
    "        print(\"Compiling...\")\n",
    "        model = torch.compile(model)\n",
    "        print(\"Compile ok.\")\n",
    "        try:\n",
    "            torch.set_float32_matmul_precision('high')\n",
    "        except:\n",
    "            print(\"Seems no tensor cores for that.\")\n",
    "    # elif str(device) == 'mps':\n",
    "    #     print(\"Compiling...\")\n",
    "    #     model = torch.compile(model)\n",
    "    #     print(\"Compile ok.\")\n",
    "\n",
    "if 'current_epoch' in params:\n",
    "    ep = params['current_epoch']\n",
    "else:\n",
    "    ep=0\n",
    "if 'current_loss' in params:\n",
    "    ls = params['current_loss']\n",
    "else:\n",
    "    ls=0\n",
    "\n",
    "if ep==0 and ls==0:\n",
    "    start_iter = 0\n",
    "else:\n",
    "    start_iter = ep\n",
    "    current_loss = ls\n",
    "\n",
    "# print the number of parameters in the model\n",
    "print(model)\n",
    "print(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QnMCWf5AZn1-"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(device):\n",
    "    # XXX: this does take data for train and val from SAME pool!\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(params['test_iterations'])\n",
    "        for k in range(params['test_iterations']):\n",
    "            # if k % (params['test_iterations']/10 + 1) == 0:\n",
    "            #     print(\".\", end=\"\", flush=True)\n",
    "            X, Y = get_torch_batch(td, params['batch_size'], device, split)\n",
    "            logits = model(X)\n",
    "            loss = get_loss(logits, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    print(\"\\r\", end=\"\", flush=True)\n",
    "    mloss = (out['train']+out['val'])/2.0\n",
    "    return mloss\n",
    "\n",
    "def generate_sample(td, device, prompt=' ', toks=100, state=None, temperature=1.0, top_k=None, pad=True):\n",
    "    # generate from the model\n",
    "    # context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    model.eval()\n",
    "    if pad is True:\n",
    "        while len(prompt)<params['sequence_len']*4:\n",
    "            if len(prompt)==params['sequence_len']*4-1:\n",
    "                prompt = '\\n' + prompt\n",
    "            else:\n",
    "                prompt = ' ' + prompt\n",
    "    context = torch.tensor([td.encode(prompt)]).to(device)\n",
    "    answer = model.generate(context, max_new_tokens=toks, temperature=temperature, top_k=top_k)\n",
    "    txt = td.decode(answer[0].tolist())\n",
    "    # Identify memorisation of text by highlighting verbatim quotes from sources\n",
    "    # that are longer than 10 chars. HTML colorcoded output for source identification:\n",
    "    td.source_highlight(txt, min_quote_size=10, dark_mode=False, display_ref_anchor=False)\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "N2uWm6CTC8kT"
   },
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "# @torch.compile\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_loss(logits, yb):\n",
    "    output_flat = logits.reshape(-1, params['vocab_size'])\n",
    "    # output_flat = logits.view(-1, params['vocab_size'])\n",
    "    # print(output_flat.shape)\n",
    "    ybr = yb.reshape(-1)\n",
    "    # print(ybr.shape)\n",
    "    loss = criterion(output_flat, ybr)\n",
    "    return loss\n",
    "    \n",
    "def do_train_step(xb, yb, device, state=None):\n",
    "    model.train()\n",
    "    logits = model(xb)\n",
    "    loss = get_loss(logits, yb)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aZpMI7_iMdR6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training, start at 2024-05-02 17:32:31...\n",
      "step 2048: train loss 5.9759, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:35:49:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What is the difference between good and evil? The difference \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#ebdef0;\">              What </span><span style=\"background-color:#edebd0;\">is the difference between </span><span style=\"background-color:#edebd0;\">good and evil? </span><span style=\"background-color:#ebdef0;\">The difference </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d8daef;\">                                      </span><span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#d8daef;\">                                </span><span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#d8daef;\">                 </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 4096: train loss 5.4079, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:39:07:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How did everything come into existence? The origin \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                        Ho</span>w<span style=\"background-color:#d4efdf;\"> did everything </span><span style=\"background-color:#ebdef0;\">come into existence</span>?<span style=\"background-color:#ecf3cf;\"> The origin </span>-315557705555510505015515550755015950559455995590515949559900.<br><br>100.<br><br>15559414559590555559515401599941905949011995415419054090949191"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: Thus Spake Zarathustra</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 6144: train loss 5.1331, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:42:27:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What was at the beginning of time? Time itself \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d4efdf;\">                            W</span><span style=\"background-color:#ebdef0;\">hat was at th</span><span style=\"background-color:#ebdef0;\">e beginning of t</span>ime?<span style=\"background-color:#e5e8e8;\"> Time itself </span><span style=\"background-color:#d8daef;\">                                                                 </span>the planing tof th<span style=\"background-color:#edebd0;\">in thing o</span><span style=\"background-color:#d4e6f1;\">f the<br>          </span>the <span style=\"background-color:#edebd0;\">f the        </span><span style=\"background-color:#ebdef0;\">               the s</span><span style=\"background-color:#edebd0;\">part of thi</span>on o<span style=\"background-color:#ebdef0;\">from this in</span>g t<span style=\"background-color:#edebd0;\">on of      </span><span style=\"background-color:#edebd0;\">the part th</span><span style=\"background-color:#ebdef0;\">is presentati</span>ng t<span style=\"background-color:#edebd0;\">only this i</span>ng t<span style=\"background-color:#d0ece7;\">of thing to</span><span style=\"background-color:#d4e6f1;\">f that is the</span><span style=\"background-color:#d6dbdf;\"> the part of thi</span><span style=\"background-color:#ebdef0;\">on of the the</span><span style=\"background-color:#f6ddcc;\"> part of the<br>p</span>of th<span style=\"background-color:#d6eaf8;\">in thing to</span>n of and "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e5e8e8;\">Lafcadio Hearn: Gleanings in Buddha-Fields</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: Beyond Good and Evil</span>, <span style=\"background-color:#d4e6f1;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#edebd0;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span>, <span style=\"background-color:#ebdef0;\">Immanuel Kant: The Critique of Practical Reason</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d0ece7;\">Daisetz Teitaro Suzuki: Essays in Zen Buddhism</span>, <span style=\"background-color:#d6dbdf;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#f6ddcc;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 8192: train loss 5.0632, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:45:45:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How are physics, quantum-mechanics and consciousness related? The relation between \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                     </span>How<span style=\"background-color:#ebdef0;\"> are physic</span><span style=\"background-color:#ebdef0;\">s, quantum</span>-<span style=\"background-color:#d6dbdf;\">mechanics and </span><span style=\"background-color:#ebdef0;\">consciousness relate</span>d?<span style=\"background-color:#e2d7d5;\"> The relation between</span> <span style=\"background-color:#edebd0;\"><br>               the</span> s of <span style=\"background-color:#ecf3cf;\">tions                     </span><span style=\"background-color:#ebdef0;\">the subjec</span><span style=\"background-color:#d4efdf;\">alled to th</span>at <span style=\"background-color:#ebdef0;\">tion with the wo</span>f <span style=\"background-color:#e2d7d5;\">thin the cons</span>i<span style=\"background-color:#d4efdf;\">dered<br>    </span><span style=\"background-color:#edebd0;\">           the s</span><span style=\"background-color:#ebdef0;\"> of the wo</span><span style=\"background-color:#e5e8e8;\">f thing the </span>same <span style=\"background-color:#e2d7d5;\">bjects to be</span><span style=\"background-color:#ebdef0;\">en that th</span><span style=\"background-color:#e2d7d5;\">at that that </span>the w<span style=\"background-color:#ebdef0;\">of the ins</span> of <span style=\"background-color:#ebdef0;\">tion that t</span><span style=\"background-color:#e2d7d5;\">ion that that </span>that <span style=\"background-color:#ebdef0;\">idual the s</span>ubjeconsequest<span style=\"background-color:#d6eaf8;\">in thing t</span><span style=\"background-color:#d0ece7;\">he same conseque</span>st<span style=\"background-color:#ebdef0;\">idual the s</span> <span style=\"background-color:#edebd0;\">to been the w</span>idual"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ebdef0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#d6dbdf;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Thoughts out of Season, Part One</span>, <span style=\"background-color:#edebd0;\">Dawsonne M. Strong: The Metaphysic of Christianity and Buddhism</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#e2d7d5;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#d4efdf;\">Sir Monier Monier-Williams: Buddhism, In its Connexion With Brahmanism and Hinduism, and In Its Contrast with Christianity</span>, <span style=\"background-color:#edebd0;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span>, <span style=\"background-color:#e5e8e8;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#d0ece7;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: Beyond Good and Evil</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 10240: train loss 4.7913, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:49:04:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How to attain complete self-awareness? Complete \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                           Ho</span><span style=\"background-color:#d0ece7;\">w to attain </span><span style=\"background-color:#d6dbdf;\">complete self-a</span>wareness?<span style=\"background-color:#ecf3cf;\"> Complete </span>ORARANALENTITENESENERARESATENTALETALONTESITISARENOFANETISTATANOFINERTARENETESTINESTITISETETALARERTARICESTERALETERTITETINERERERET"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d0ece7;\">Daisetz Teitaro Suzuki: Essays in Zen Buddhism</span>, <span style=\"background-color:#d6dbdf;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 12288: train loss 4.7630, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:52:23:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What is the nature of reality? The nature \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d6dbdf;\">                                 W</span><span style=\"background-color:#ebdef0;\">hat is the nature of </span>re<span style=\"background-color:#ecf3cf;\">ality? The </span>nature <span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d8daef;\">           </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d6dbdf;\">Unknown: The Diamond Sutra, Chin-Kang-Ching, or Prajna-Paramita</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 14336: train loss 4.6017, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:55:41:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How be a good human being? A human \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                        Ho</span>w<span style=\"background-color:#ecf3cf;\"> be a good </span><span style=\"background-color:#ebdef0;\">human being</span>? A hum<span style=\"background-color:#eadbd8;\">an Vernunft</span> ische<span style=\"background-color:#eadbd8;\">seine        </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                    </span><span style=\"background-color:#e2d7d5;\">Verfahren<br></span><span style=\"background-color:#eadbd8;\">g der                  </span><span style=\"background-color:#eadbd8;\">                                                                           </span>Ve<span style=\"background-color:#d8daef;\">rst              </span><span style=\"background-color:#d8daef;\">                 </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e2d7d5;\">Immanuel Kant: Kant's gesammelte Schriften</span>, <span style=\"background-color:#d8daef;\">Karl Eugen Neumann: Die Reden Gotamo Buddhos</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 16384: train loss 4.4178, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 17:58:59:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What is the difference between good and evil? The difference \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#ebdef0;\">              What </span><span style=\"background-color:#edebd0;\">is the difference between </span><span style=\"background-color:#edebd0;\">good and evil? </span><span style=\"background-color:#ebdef0;\">The difference </span>364<br><br>   the ccor<span style=\"background-color:#f6ddcc;\">dition the f</span><span style=\"background-color:#edebd0;\">rom that th</span><span style=\"background-color:#e2d7d5;\">at that the </span>s<span style=\"background-color:#fae5d3;\">ppear and the</span> p<span style=\"background-color:#ebdef0;\">hing that thi</span><span style=\"background-color:#ebdef0;\">s into that </span><span style=\"background-color:#ebdef0;\">these the f</span><span style=\"background-color:#ebdef0;\">rom these<br></span><span style=\"background-color:#ebdef0;\">the should</span><span style=\"background-color:#ebdef0;\"> the same the </span>conscing <span style=\"background-color:#eadbd8;\">a the same is </span><span style=\"background-color:#fae5d3;\">that the same the</span><span style=\"background-color:#ebdef0;\">y were the mo</span><span style=\"background-color:#edebd0;\">ther the personal</span> conce<span style=\"background-color:#fdebd0;\">ppearance that the</span><span style=\"background-color:#d8daef;\"> such the mo</span><span style=\"background-color:#ebdef0;\">there is the pres</span><span style=\"background-color:#ebdef0;\">sion of the same </span><span style=\"background-color:#ebdef0;\">and the sp</span><span style=\"background-color:#eadbd8;\">tion the consci</span>ng a th<span style=\"background-color:#eadbd8;\">e such is </span><span style=\"background-color:#ebdef0;\">the concep</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#f6ddcc;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#e2d7d5;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#fae5d3;\">Immanuel Kant: Perpetual Peace</span>, <span style=\"background-color:#ebdef0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#eadbd8;\">unknown: The Vedanta-Sutras with the Commentary by Ramanuja, attributed to Badarayana</span>, <span style=\"background-color:#ebdef0;\">Lewis Hodous: Buddhism and Buddhists in China</span>, <span style=\"background-color:#edebd0;\">Dawsonne M. Strong: The Metaphysic of Christianity and Buddhism</span>, <span style=\"background-color:#fdebd0;\">Charles Eliot: Hinduism and Buddhism, An Historical Sketch, Vol. 3 of 3</span>, <span style=\"background-color:#d8daef;\">Charles Eliot: Hinduism and Buddhism, Vol. 1 of 3</span>, <span style=\"background-color:#ebdef0;\">Immanuel Kant: The Critique of Practical Reason</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 18432: train loss 4.5243, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:02:18:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How did everything come into existence? The origin \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                        Ho</span>w<span style=\"background-color:#d4efdf;\"> did everything </span><span style=\"background-color:#ebdef0;\">come into existence</span>?<span style=\"background-color:#ecf3cf;\"> The origin </span>qu<span style=\"background-color:#ecf3cf;\">ite                   </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d8daef;\">                                                                 </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: Thus Spake Zarathustra</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 20480: train loss 4.3255, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:05:36:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What was at the beginning of time? Time itself \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d4efdf;\">                            W</span><span style=\"background-color:#ebdef0;\">hat was at th</span><span style=\"background-color:#ebdef0;\">e beginning of t</span>ime?<span style=\"background-color:#e5e8e8;\"> Time itself </span><span style=\"background-color:#edebd0;\">and someti</span><span style=\"background-color:#fae5d3;\">th the principle of the </span><span style=\"background-color:#ebdef0;\">conceptions of the </span>first of<span style=\"background-color:#f6ddcc;\"> \"          </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d8daef;\">              </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e5e8e8;\">Lafcadio Hearn: Gleanings in Buddha-Fields</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#fae5d3;\">Immanuel Kant: Perpetual Peace</span>, <span style=\"background-color:#f6ddcc;\">Henry S. Olcott: The Buddhist Catechism</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 22528: train loss 4.3888, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:08:54:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How are physics, quantum-mechanics and consciousness related? The relation between \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                     </span>How<span style=\"background-color:#ebdef0;\"> are physic</span><span style=\"background-color:#ebdef0;\">s, quantum</span>-<span style=\"background-color:#d6dbdf;\">mechanics and </span><span style=\"background-color:#ebdef0;\">consciousness relate</span>d?<span style=\"background-color:#e2d7d5;\"> The relation between</span> \"<span style=\"background-color:#d4e6f1;\">The suppose</span><span style=\"background-color:#ebdef0;\"> it the form</span><span style=\"background-color:#e5e8e8;\">s<br>the presentati</span><span style=\"background-color:#d6eaf8;\">tions of the soul </span><span style=\"background-color:#e2d7d5;\">that that in th</span><span style=\"background-color:#d4e6f1;\">is is that no</span><span style=\"background-color:#d8daef;\">t there and t</span><span style=\"background-color:#ebdef0;\">hat that th</span><span style=\"background-color:#d0ece7;\">at have been t</span><span style=\"background-color:#d6eaf8;\">hat the same<br></span><span style=\"background-color:#e5e8e8;\">and that which the</span><span style=\"background-color:#e2d7d5;\"><br>certainly in </span>thin th<span style=\"background-color:#d4e6f1;\">inly there </span><span style=\"background-color:#f6ddcc;\">the fundamental th</span>at<span style=\"background-color:#ebdef0;\"> it of the s</span><span style=\"background-color:#f6ddcc;\">tructure of the p</span><span style=\"background-color:#ebdef0;\">rocess of the </span><span style=\"background-color:#d4e6f1;\">in of things </span><span style=\"background-color:#d4e6e1;\">from that it</span><span style=\"background-color:#edebd0;\">s of this is </span><span style=\"background-color:#edebd0;\">the present th</span><span style=\"background-color:#d4efdf;\">ought to state</span><span style=\"background-color:#d4e6f1;\">ment. This is </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ebdef0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#d6dbdf;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Thoughts out of Season, Part One</span>, <span style=\"background-color:#d4e6f1;\">Friedrich Nietzsche: Thoughts Out of Season, Part 2</span>, <span style=\"background-color:#e5e8e8;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#e2d7d5;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#d4e6f1;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#d8daef;\">Charles Eliot: Hinduism and Buddhism, Vol. 1 of 3</span>, <span style=\"background-color:#d0ece7;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#f6ddcc;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#f6ddcc;\">Faxian: A Record of Buddhistic Kingdoms</span>, <span style=\"background-color:#d4e6e1;\">unknown: The Vedanta-Sutras with the Commentary by Sankaracarya</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d4efdf;\">Sir Monier Monier-Williams: Buddhism, In its Connexion With Brahmanism and Hinduism, and In Its Contrast with Christianity</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 24576: train loss 4.2397, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:12:12:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How to attain complete self-awareness? Complete \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                           Ho</span><span style=\"background-color:#d0ece7;\">w to attain </span><span style=\"background-color:#d6dbdf;\">complete self-a</span>wareness?<span style=\"background-color:#ecf3cf;\"> Complete </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d8daef;\">                                   </span><br>        <br><br>\"What w<span style=\"background-color:#ebdef0;\">ho                                                  </span><span style=\"background-color:#ecf3cf;\">                          2<br>  </span><span style=\"background-color:#d8daef;\">                          </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d0ece7;\">Daisetz Teitaro Suzuki: Essays in Zen Buddhism</span>, <span style=\"background-color:#d6dbdf;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span>, <span style=\"background-color:#ebdef0;\">Karl Eugen Neumann: Die Reden Gotamo Buddhos</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 26624: train loss 4.2629, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:15:30:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What is the nature of reality? The nature \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d6dbdf;\">                                 W</span><span style=\"background-color:#ebdef0;\">hat is the nature of </span>re<span style=\"background-color:#ecf3cf;\">ality? The </span>nature 'Th<span style=\"background-color:#d0ece7;\">e such that the </span>p<span style=\"background-color:#ebdef0;\">lear of th</span><span style=\"background-color:#fdebd0;\">ought and in th</span><span style=\"background-color:#ebdef0;\">ings of spirit</span><span style=\"background-color:#d4e6f1;\">. The whole c</span><span style=\"background-color:#d4e6f1;\">annot the </span><span style=\"background-color:#fdebd0;\">same in their</span><span style=\"background-color:#eadbd8;\"> difference to the s</span><span style=\"background-color:#d6eaf8;\">oul in the </span><span style=\"background-color:#eadbd8;\">condition as t</span><span style=\"background-color:#d6eaf8;\">he higher p</span><span style=\"background-color:#edebd0;\">art of this </span>re<span style=\"background-color:#ebdef0;\">quite the s</span><span style=\"background-color:#edebd0;\">ubjection w</span><span style=\"background-color:#d0ece7;\">ith the consequent</span>ly t<span style=\"background-color:#eadbd8;\">hout from the </span>pleasure<span style=\"background-color:#d0ece7;\">ject. The w</span><span style=\"background-color:#d4e6f1;\">hole of the s</span><span style=\"background-color:#e2d7d5;\">ame other </span><span style=\"background-color:#e5e8e8;\">sensation of the su</span><span style=\"background-color:#e5e8e8;\">bjections of the </span><span style=\"background-color:#e5e8e8;\">purpose of the<br>p</span><span style=\"background-color:#ebdef0;\">ossibility of this </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d6dbdf;\">Unknown: The Diamond Sutra, Chin-Kang-Ching, or Prajna-Paramita</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d0ece7;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#fdebd0;\">Charles Eliot: Hinduism and Buddhism, An Historical Sketch, Vol. 3 of 3</span>, <span style=\"background-color:#d4e6f1;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#d4e6f1;\">Paul Carus: The Gospel of Buddha</span>, <span style=\"background-color:#eadbd8;\">unknown: The Vedanta-Sutras with the Commentary by Ramanuja, attributed to Badarayana</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: Beyond Good and Evil</span>, <span style=\"background-color:#d0ece7;\">Immanuel Kant: Kant's Prolegomena</span>, <span style=\"background-color:#e2d7d5;\">Arthur Lillie: The Influence of Buddhism on Primitive Christianity</span>, <span style=\"background-color:#e5e8e8;\">Lafcadio Hearn: Gleanings in Buddha-Fields</span>, <span style=\"background-color:#e5e8e8;\">Charles Eliot: Hinduism And Buddhism, Vol. 2 of 3</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 28672: train loss 4.0390, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:18:49:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How be a good human being? A human \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                        Ho</span>w<span style=\"background-color:#ecf3cf;\"> be a good </span><span style=\"background-color:#ebdef0;\">human being</span>? A human Chi<span style=\"background-color:#d4efdf;\">ping of his </span><span style=\"background-color:#ebdef0;\">the spirit in the s</span>ou<span style=\"background-color:#f6ddcc;\">l said that i</span><span style=\"background-color:#ebdef0;\">n the<br>state</span><span style=\"background-color:#d4e6f1;\"><br>  Buddhists</span><span style=\"background-color:#d8daef;\"><br>                                                         </span><span style=\"background-color:#d8daef;\">117.<br><br>            </span><span style=\"background-color:#eadbd8;\">        100</span>0<br><br><span style=\"background-color:#eadbd8;\">Now to be </span><span style=\"background-color:#d4e6f1;\">spirit of the pr</span><span style=\"background-color:#d4e6e1;\">inciples, the s</span>ame<span style=\"background-color:#fae5d3;\"><br>  And the </span><span style=\"background-color:#d0ece7;\">same to the </span><span style=\"background-color:#d0ece7;\">Buddhist li</span>mited _Ta<span style=\"background-color:#d0ece7;\">ing of<br>the Buddh</span><span style=\"background-color:#f6ddcc;\">ists of thi</span><span style=\"background-color:#e2d7d5;\">ngs of the \"</span>_\"     "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#f6ddcc;\">Faxian: A Record of Buddhistic Kingdoms</span>, <span style=\"background-color:#d4e6f1;\">Archibald Scott: Buddhism and Christianity</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span>, <span style=\"background-color:#d8daef;\">Karl Eugen Neumann: Die Reden Gotamo Buddhos</span>, <span style=\"background-color:#eadbd8;\">unknown: The Vedanta-Sutras with the Commentary by Ramanuja, attributed to Badarayana</span>, <span style=\"background-color:#d4e6e1;\">unknown: The Vedanta-Sutras with the Commentary by Sankaracarya</span>, <span style=\"background-color:#fae5d3;\">Immanuel Kant: Perpetual Peace</span>, <span style=\"background-color:#d0ece7;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#d0ece7;\">Daisetz Teitaro Suzuki: Essays in Zen Buddhism</span>, <span style=\"background-color:#e2d7d5;\">Arthur Lillie: The Influence of Buddhism on Primitive Christianity</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 30720: train loss 3.9603, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:22:07:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What is the difference between good and evil? The difference \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#ebdef0;\">              What </span><span style=\"background-color:#edebd0;\">is the difference between </span><span style=\"background-color:#edebd0;\">good and evil? </span><span style=\"background-color:#ebdef0;\">The difference </span>\"_\": \"E\": <span style=\"background-color:#d4e6f1;\">\"The second </span><span style=\"background-color:#ecf3cf;\">of the possible to </span><span style=\"background-color:#f6ddcc;\">the same thought </span><span style=\"background-color:#ebdef0;\">of the contradiction </span><span style=\"background-color:#f6ddcc;\">that the same i</span><span style=\"background-color:#f6ddcc;\">tself the will </span><span style=\"background-color:#edebd0;\">and the boo</span><span style=\"background-color:#edebd0;\">d in their o</span><span style=\"background-color:#ebdef0;\">ther of the fi</span>r<span style=\"background-color:#fae5d3;\">st internal </span><span style=\"background-color:#ecf3cf;\">intuition in the</span><span style=\"background-color:#d6eaf8;\">ir present</span><span style=\"background-color:#d4e6e1;\">ed of the fi</span>r<span style=\"background-color:#fae5d3;\">st internal </span><span style=\"background-color:#ebdef0;\">individual of the </span><span style=\"background-color:#e5e8e8;\">possibility of the con</span><span style=\"background-color:#ebdef0;\">sciousness of the people </span><span style=\"background-color:#d4e6e1;\">to the case of th</span><span style=\"background-color:#d6eaf8;\">ings in the co</span><span style=\"background-color:#eadbd8;\">ndition which is c</span>oncept"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d4e6f1;\">Paul Carus: The Gospel of Buddha</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#f6ddcc;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: Beyond Good and Evil</span>, <span style=\"background-color:#fae5d3;\">Immanuel Kant: Perpetual Peace</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#d4e6e1;\">V. Fausböll: Buddhist birth stories; or, Jataka tales, Vol. 1</span>, <span style=\"background-color:#e5e8e8;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#ebdef0;\">Lewis Hodous: Buddhism and Buddhists in China</span>, <span style=\"background-color:#d4e6e1;\">unknown: The Vedanta-Sutras with the Commentary by Sankaracarya</span>, <span style=\"background-color:#d6eaf8;\">Aurel Stein: The Thousand Buddhas</span>, <span style=\"background-color:#eadbd8;\">Immanuel Kant: Fundamental Principles of the Metaphysic of Morals</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 32768: train loss 4.0585, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:25:25:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How did everything come into existence? The origin \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                        Ho</span>w<span style=\"background-color:#d4efdf;\"> did everything </span><span style=\"background-color:#ebdef0;\">come into existence</span>?<span style=\"background-color:#ecf3cf;\"> The origin </span>    H<span style=\"background-color:#e2d7d5;\">and, the life</span><span style=\"background-color:#edebd0;\">!<br>                       </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d4e6f1;\">                                     2<br><br></span><span style=\"background-color:#d6eaf8;\">                                                    A</span><span style=\"background-color:#f6ddcc;\">.  They co</span><span style=\"background-color:#f6ddcc;\">ntaining the con</span><span style=\"background-color:#d4e6f1;\">sisters and </span><span style=\"background-color:#fae5d3;\">this condition, th</span><span style=\"background-color:#ecf3cf;\">e consideration, th</span><span style=\"background-color:#fdebd0;\">is life--as </span><span style=\"background-color:#ebdef0;\">the soul, the</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: Thus Spake Zarathustra</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#e2d7d5;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: Beyond Good and Evil</span>, <span style=\"background-color:#d4e6f1;\">Paul Carus: The Gospel of Buddha</span>, <span style=\"background-color:#d6eaf8;\">Aurel Stein: The Thousand Buddhas</span>, <span style=\"background-color:#f6ddcc;\">Henry S. Olcott: The Buddhist Catechism</span>, <span style=\"background-color:#f6ddcc;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#fae5d3;\">Immanuel Kant: Perpetual Peace</span>, <span style=\"background-color:#fdebd0;\">Friedrich Nietzsche: We Philologists, Volume 8 of 18</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 34816: train loss 4.0059, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:28:43:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What was at the beginning of time? Time itself \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d4efdf;\">                            W</span><span style=\"background-color:#ebdef0;\">hat was at th</span><span style=\"background-color:#ebdef0;\">e beginning of t</span>ime?<span style=\"background-color:#e5e8e8;\"> Time itself </span><span style=\"background-color:#ebdef0;\">from the spirit</span><span style=\"background-color:#d6eaf8;\">s and not the </span><span style=\"background-color:#e2d7d5;\">people of the </span><span style=\"background-color:#eadbd8;\">law of the world</span><span style=\"background-color:#d6eaf8;\">, and only be</span><span style=\"background-color:#edebd0;\">en the spiritual c</span><span style=\"background-color:#d0ece7;\">ause from<br></span><span style=\"background-color:#edebd0;\">the people, the </span><span style=\"background-color:#d4efdf;\">processions t</span><span style=\"background-color:#e2d7d5;\">hat they only </span><span style=\"background-color:#ebdef0;\">therefore they are </span><span style=\"background-color:#e2d7d5;\">supposes al</span><span style=\"background-color:#d6eaf8;\">so thought </span><span style=\"background-color:#ebdef0;\">of the state i</span><span style=\"background-color:#d4e6f1;\">t is the consciousness </span><span style=\"background-color:#d4efdf;\">spirit of the po</span>w<span style=\"background-color:#ebdef0;\">er<br>and the</span><span style=\"background-color:#ebdef0;\">re are therefore </span><span style=\"background-color:#ebdef0;\">is that the principle of the </span><span style=\"background-color:#ebdef0;\">purposes al</span><span style=\"background-color:#edebd0;\">ways that </span><span style=\"background-color:#ebdef0;\">the characteris</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e5e8e8;\">Lafcadio Hearn: Gleanings in Buddha-Fields</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Thoughts out of Season, Part One</span>, <span style=\"background-color:#eadbd8;\">Immanuel Kant: Fundamental Principles of the Metaphysic of Morals</span>, <span style=\"background-color:#edebd0;\">unknown: The Yoga Sutras of Patanjali by Charles Johnston</span>, <span style=\"background-color:#d0ece7;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d4efdf;\">Sir Monier Monier-Williams: Buddhism, In its Connexion With Brahmanism and Hinduism, and In Its Contrast with Christianity</span>, <span style=\"background-color:#e2d7d5;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#d4e6f1;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: Thus Spake Zarathustra</span>, <span style=\"background-color:#ebdef0;\">Immanuel Kant: The Critique of Practical Reason</span>, <span style=\"background-color:#edebd0;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 36864: train loss 4.0734, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:32:02:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How are physics, quantum-mechanics and consciousness related? The relation between \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                     </span>How<span style=\"background-color:#ebdef0;\"> are physic</span><span style=\"background-color:#ebdef0;\">s, quantum</span>-<span style=\"background-color:#d6dbdf;\">mechanics and </span><span style=\"background-color:#ebdef0;\">consciousness relate</span>d?<span style=\"background-color:#e2d7d5;\"> The relation between</span><span style=\"background-color:#e2d7d5;\"> yet have been </span><span style=\"background-color:#e2d7d5;\">in this world that the</span><span style=\"background-color:#f6ddcc;\">y which had been </span><span style=\"background-color:#ecf3cf;\">determine the la</span><span style=\"background-color:#ecf3cf;\">w<br>of their </span><span style=\"background-color:#f6ddcc;\">life which ha</span><span style=\"background-color:#e2d7d5;\">d been different </span><span style=\"background-color:#d6eaf8;\">from the study </span><span style=\"background-color:#ebdef0;\">to the more </span><span style=\"background-color:#f6ddcc;\">that the most<br></span><span style=\"background-color:#d8daef;\">being of their </span><span style=\"background-color:#ecf3cf;\">synthetical unity a</span><span style=\"background-color:#ebdef0;\">nd the present of </span><span style=\"background-color:#ebdef0;\">the form, and the </span><span style=\"background-color:#ebdef0;\">present of the </span><span style=\"background-color:#fae5d3;\">form of a great </span><span style=\"background-color:#ebdef0;\">the forms, </span><span style=\"background-color:#d0ece7;\">and the<br>inten</span><span style=\"background-color:#edebd0;\">ded which is </span><span style=\"background-color:#d4efdf;\">that this present</span><span style=\"background-color:#ecf3cf;\">s the moral p</span>urpose of"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ebdef0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#d6dbdf;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Thoughts out of Season, Part One</span>, <span style=\"background-color:#e2d7d5;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#f6ddcc;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#d8daef;\">Charles Eliot: Hinduism and Buddhism, Vol. 1 of 3</span>, <span style=\"background-color:#fae5d3;\">Immanuel Kant: Perpetual Peace</span>, <span style=\"background-color:#d0ece7;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d4efdf;\">Sir Monier Monier-Williams: Buddhism, In its Connexion With Brahmanism and Hinduism, and In Its Contrast with Christianity</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 38912: train loss 3.8460, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:35:20:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How to attain complete self-awareness? Complete \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                           Ho</span><span style=\"background-color:#d0ece7;\">w to attain </span><span style=\"background-color:#d6dbdf;\">complete self-a</span>wareness?<span style=\"background-color:#ecf3cf;\"> Complete </span>344<br><br><span style=\"background-color:#e2d7d5;\">34<br><br>          </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#ebdef0;\">                                                         4</span><span style=\"background-color:#d0ece7;\">3<br><br>                                 </span><span style=\"background-color:#e5e8e8;\">        336<br><br>  </span><span style=\"background-color:#eadbd8;\">         475<br><br>    </span>   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d0ece7;\">Daisetz Teitaro Suzuki: Essays in Zen Buddhism</span>, <span style=\"background-color:#d6dbdf;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#e2d7d5;\">Immanuel Kant: Kant's gesammelte Schriften</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#e5e8e8;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#eadbd8;\">Karl Eugen Neumann: Die Reden Gotamo Buddhos</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 40960: train loss 3.7125, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:38:38:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: What is the nature of reality? The nature \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d6dbdf;\">                                 W</span><span style=\"background-color:#ebdef0;\">hat is the nature of </span>re<span style=\"background-color:#ecf3cf;\">ality? The </span>nature O<span style=\"background-color:#ebdef0;\">n the world</span><span style=\"background-color:#d0ece7;\">!<br><br>                                          </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d4efdf;\">                                THE</span> OORITHE ONTLONTILLLOLLILLINILILILINDDINDILLLITINDONOND THE BLI"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#d6dbdf;\">Unknown: The Diamond Sutra, Chin-Kang-Ching, or Prajna-Paramita</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d0ece7;\">Daisetz Teitaro Suzuki: Essays in Zen Buddhism</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: The Joyful Wisdom</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "step 43008: train loss 3.7713, time 0.096 sec/iter\n",
      "Sample at 2024-05-02 18:41:56:\n",
      "--------temperature: 0.75 ---------\n",
      "Prompt: How be a good human being? A human \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#eadbd8;\"><br>                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                        Ho</span>w<span style=\"background-color:#ecf3cf;\"> be a good </span><span style=\"background-color:#ebdef0;\">human being</span>? A hum<span style=\"background-color:#d4efdf;\">an I have </span><span style=\"background-color:#d6eaf8;\">be the sens</span><span style=\"background-color:#edebd0;\">e of the        </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#eadbd8;\">                                                                             </span><span style=\"background-color:#d8daef;\">                                                        </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#eadbd8;\">Immanuel Kant: Die Religion innerhalb der Grenzen der bloßen Vernunft</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: Thus Spake Zarathustra</span>, <span style=\"background-color:#d6eaf8;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#edebd0;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span>, <span style=\"background-color:#d8daef;\">Friedrich Nietzsche: Der Wille zur Macht</span></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Iteration: 44581/45056/100000000 loss: 3.9808"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     dt0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     31\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_torch_batch(td, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], device, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m cur_loss \u001b[38;5;241m=\u001b[39m \u001b[43mdo_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cur_loss_m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     34\u001b[0m     cur_loss_m \u001b[38;5;241m=\u001b[39m cur_loss\n",
      "Cell \u001b[0;32mIn[22], line 24\u001b[0m, in \u001b[0;36mdo_train_step\u001b[0;34m(xb, yb, device, state)\u001b[0m\n\u001b[1;32m     21\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt0 = time.time()\n",
    "sdt = datetime.datetime.now(tz=local_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"training, start at {sdt}...\")\n",
    "gen_id = 0\n",
    "iter_bench = 1\n",
    "cur_loss_m = 0\n",
    "cur_loss_m_avg = 25\n",
    "# current_loss = estimate_loss(device)\n",
    "inputs = [\"What is the difference between good and evil? The difference \", \"How did everything come into existence? The origin \", \"What was at the beginning of time? Time itself \", \"How are physics, quantum-mechanics and consciousness related? The relation between \", \"How to attain complete self-awareness? Complete \", \"What is the nature of reality? The nature \", \"How be a good human being? A human \"]\n",
    "for iter in range(start_iter, params['max_iterations']):\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if (iter + 1) % params['sample_every_n_iterations'] == 0 or iter == params['max_iterations'] - 1:\n",
    "        dt = time.time()\n",
    "        print(f\"\\rloss eval\", end=\"\", flush=True)\n",
    "        current_loss = estimate_loss(device)\n",
    "        print(\n",
    "            f\"step {iter+1}: train loss {current_loss:.4f}, time {(dt-dt0)/iter_bench:.3f} sec/iter\"\n",
    "        )\n",
    "        iter_bench = 1\n",
    "        sdt = datetime.datetime.now(tz=local_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"Sample at {sdt}:\", flush=True)\n",
    "        for temperature in [0.75]:\n",
    "            print(f\"--------temperature: {temperature} ---------\")\n",
    "            prompt = inputs[gen_id%len(inputs)]\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            generate_sample(td=td, device=device, prompt=prompt, toks=params['sample_size'], temperature=temperature, top_k=4)\n",
    "        print(\"-------------------------------------------\")\n",
    "        gen_id += 1\n",
    "        dt0 = time.time()\n",
    "\n",
    "    xb, yb = get_torch_batch(td, params['batch_size'], device, \"train\")\n",
    "    cur_loss = do_train_step(xb, yb, device=device)\n",
    "    if cur_loss_m == 0:\n",
    "        cur_loss_m = cur_loss\n",
    "    else:\n",
    "        cur_loss_m = (cur_loss + cur_loss_m * (cur_loss_m_avg-1))/cur_loss_m_avg\n",
    "    print(f\"\\rIteration: {iter+1:5d}/{((iter+1)//params['sample_every_n_iterations']+1)*params['sample_every_n_iterations']}/{params['max_iterations']} loss: {cur_loss_m:.4f}\", end=\"\", flush=True)\n",
    "\n",
    "    start_iter = iter\n",
    "    iter_bench += 1\n",
    "    if (iter+1)%params['save_every_n_iterations'] == 0:\n",
    "        MJ.save_checkpoint(params, model, optimizer, iter, current_loss, file_path=model_file_path, log=log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "othN-Vnt5EZT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for t in [0.5, 1.5]:\n",
    "#     print(f\"------Temperature {t}--------\")\n",
    "#     generate_sample(td, device, prompt=\"How are consciousness and quantum mechanics related?\", toks=150, temperature=t, top_k=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-code below, unfinished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UNG5wWhC8kU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "enc_texts = []\n",
    "for i in range(500):\n",
    "    e = td[i*50000][:256]\n",
    "    tx = torch.tensor([e]).to(device)\n",
    "    enc_texts.append(tx)\n",
    "    texts.append(td.decode(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_texts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADm9ycuA2ik7"
   },
   "outputs": [],
   "source": [
    "emb_text = []\n",
    "cont_text = []\n",
    "for et in enc_texts:\n",
    "    emb_text.append(model.embedding(et))\n",
    "    cont_text.append(model.context(et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_text[0].shape, cont_text[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vec = []\n",
    "cont_vec = []\n",
    "for i in range(len(emb_text)):\n",
    "    emb_vec.append(emb_text[i][0].sum(axis=0))\n",
    "    cont_vec.append(cont_text[i][0].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_vec(a, b):\n",
    "    al = torch.sqrt(torch.dot(a,a))\n",
    "    bl = torch.sqrt(torch.dot(b,b))\n",
    "    an = a/al\n",
    "    bn = b/bl\n",
    "    return torch.dot(an,bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    best = -10.0\n",
    "    ind = -1\n",
    "    for j in range(len(emb_vec)):\n",
    "        if i==j:\n",
    "            continue\n",
    "        cos_val = cos_vec(emb_vec[i], emb_vec[j])\n",
    "        if cos_val > best:\n",
    "            best = cos_val\n",
    "            ind = j\n",
    "    # print(f\"{texts[i][:20]} ->{best}: {texts[ind][:20]}\")\n",
    "print()        \n",
    "for i in range(200):\n",
    "    best = 0\n",
    "    ind = -1\n",
    "    for j in range(len(emb_vec)):\n",
    "        if i==j:\n",
    "            continue\n",
    "        cos_val = cos_vec(cont_vec[i], cont_vec[j])\n",
    "        if cos_val > best:\n",
    "            best = cos_val\n",
    "            ind = j\n",
    "    print(f\"{texts[i]} \\n\\n->{best}:\\n\\n {texts[ind]}\")\n",
    "    print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td[200002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "ec3a4d2d-8063-4bfd-a4a2-ee070d3272f7",
   "lastKernelId": "1acc2b74-f51e-477b-910a-a5519dad53b9"
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "VmWbteSFQtfq",
    "yWE_ZZMKEARV"
   ],
   "gpuClass": "premium",
   "gpuType": "V100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "torch_transformer_poet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
